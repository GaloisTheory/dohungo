# dohungo ğŸ¯ : A Research-Oriented Go Bot

> âš ï¸ **Work in Progress**: This bot is under active development. 

`dohungo` is a compact, research-oriented Go bot aimed at reproducing strong supervised CNN policies (â‰ˆ2-dan level) trained on KGS high-dan SGF records. The ultimate goal is to develop a bot capable of beating a 4-dan human player. Further I hope to use the trained bot to do research into the net as well. 

**ğŸ‘‰ [Quickstart Notebook](notebooks/quickstart.ipynb)** - Interactive demo showing the complete pipeline from SGF download to move prediction in ~10 minutes.

The notebook demonstrates:
- SGF game record downloading and parsing
- Board position encoding (7-plane and 11-plane encoders)
- CNN training with real-time metrics
- Move prediction visualization

## Quick Start

### Option 1: Interactive Demo 
```bash
git clone https://github.com/<you>/dohungo.git
cd dohungo
pip install -r requirements.txt
jupyter notebook notebooks/quickstart.ipynb
```

### Option 2: Full Training (WIP)
```bash
python -m dohungo.train --config configs/small.yaml
```

### Option 3: Play Against Trained Model (WIP)
```bash
python -m dohungo.play --model checkpoints/best.pt
```

## Repository Structure
```
dohungo/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ downloader.py      # SGF file downloading from u-go.net
â”‚   â”œâ”€â”€ sgf_reader.py      # SGF parsing and position extraction
â”‚   â”œâ”€â”€ encoders/          # Board position encoders
â”‚   â”‚   â”œâ”€â”€ base.py        # Abstract encoder interface
â”‚   â”‚   â”œâ”€â”€ sevenplane.py  # 7-plane encoder implementation  
â”‚   â”‚   â””â”€â”€ simple.py      # 11-plane encoder implementation
â”‚   â””â”€â”€ dataloader.py      # PyTorch data loading pipeline
â”œâ”€â”€ models/
â”‚   â””â”€â”€ cnn_small.py       # CNN architecture (~450k parameters)
â”œâ”€â”€ train.py               # CLI training entry-point
â””â”€â”€ play.py               # Interactive play interface

configs/
â””â”€â”€ small.yaml            # Training configuration

notebooks/
â””â”€â”€ quickstart.ipynb      # ğŸ““ Interactive demo (START HERE)
```

## Research Roadmap

### Phase 1: Supervised Learning (Current)
- âœ… **Baseline CNN**: Strong supervised policy from high-dan games
- ğŸš§ **Encoder ablations**: Quantify value of different input planes (liberties, ko detection)

### Phase 2: Reinforcement Learning (Next)
- ğŸ¤– **Self-play training**: Policy gradient fine-tuning with GPU acceleration
- ğŸ¯ **Strength evaluation**: Systematic testing against known benchmarks
- ğŸ† **Target strength**: Beat 4-dan human player consistently

### Phase 3: Mechanistic Interpretability (Future - Ambitious ideas)
- ğŸ“Š **Opening bias detection**: Compare learned patterns across different training datasets

## Technical Features

- **Fully deterministic**: Reproducible training with fixed random seeds
- **CPU/GPU compatible**: Runs efficiently on both CPU and GPU
- **Streaming data**: Memory-efficient SGF processing for large datasets  
- **Extensible design**: Clean interfaces for future model architectures
- **Research-ready**: Structured for systematic ablation studies

## Dependencies

- Python 3.9+
- PyTorch â‰¥2.1.0
- OmegaConf (YAML configuration)
- gomill (SGF parsing)
- NumPy, matplotlib, tqdm, pytest

## Testing

```bash 
pytest -q  # Quick test suite (~10 seconds)
```

---

**Research Goal**: Build a systematically improvable Go bot that reaches 4-dan strength.

MIT License â€¢ Â© 2025 Dohun Lee